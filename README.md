Fake News Classification with BERT

This project focuses on detecting fake news using a fine-tuned BERT model. The dataset is preprocessed, tokenized, and used to train a transformer-based classifier.

Features

Preprocessing and filtering of a large fake news dataset

Tokenization using a BERT tokenizer

Fine-tuning of a lightweight BERT model (google/bert_uncased_L-2_H-128_A-2)

Train-test-validation split for model evaluation

Trainer-based training using transformers library

FP16 acceleration for faster training

Dataset

Note: The datasets are not included in this repository due to their large size. (LIAR dataset, WELFake dataset, BS detector dataset)
